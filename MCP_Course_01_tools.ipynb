{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx1wlBsuJK5VEFY4L4lXFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farhaj499/MCP_Model_Context_Protocol_Course/blob/main/MCP_Course_01_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv\n",
        "!pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgBTSx8Jt-75",
        "outputId": "3ec3236b-438e-454d-e445-ae6f92b0026b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.4.26)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=a97fe19a2e6f46df85a0d709973d5226a595fe9b87f8eb9a6567af8fbcbed64e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.2.0 feedparser-6.0.11 sgmllib3k-1.0.0\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.0)\n",
            "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "CLAUDE_API_KEY = userdata.get('CLAUDE_API_KEY')\n"
      ],
      "metadata": {
        "id": "Jo6005p6zvVr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eSxLyOVuIzJ",
        "outputId": "ebcea93a-628e-4acc-982d-e68ec983572b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "t_emdPcittc-"
      },
      "outputs": [],
      "source": [
        "# allow searching for research papers from arxiv database\n",
        "import arxiv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import anthropic"
      ],
      "metadata": {
        "id": "SWbRW_Tut13i"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file\n",
        "(title, authors, summary, paper url and the publication date).\n",
        "The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
      ],
      "metadata": {
        "id": "LGaqQEg7wcT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_DIR = \"papers\""
      ],
      "metadata": {
        "id": "CvBziFlmuTim"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool to search papers"
      ],
      "metadata": {
        "id": "Jx3bbMoxwn7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    Search for papers on arXiv based on a topic and store their information.\n",
        "\n",
        "    Args:\n",
        "        topic: The topic to search for\n",
        "        max_results: Maximum number of results to retrieve (default: 5)\n",
        "\n",
        "    Returns:\n",
        "        List of paper IDs found in the search\n",
        "    \"\"\"\n",
        "\n",
        "    # Use arxiv to find the papers\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the most relevant articles matching the queried topic\n",
        "    search = arxiv.Search(\n",
        "        query = topic,\n",
        "        max_results = max_results,\n",
        "        sort_by = arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    papers = client.results(search)\n",
        "\n",
        "    # Create directory for this topic\n",
        "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(path, \"papers_info.json\")\n",
        "\n",
        "    # Try to load existing papers info\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            papers_info = json.load(json_file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        papers_info = {}\n",
        "\n",
        "    # Process each paper and add to papers_info\n",
        "    paper_ids = []\n",
        "    for paper in papers:\n",
        "        paper_ids.append(paper.get_short_id())\n",
        "        paper_info = {\n",
        "            'title': paper.title,\n",
        "            'authors': [author.name for author in paper.authors],\n",
        "            'summary': paper.summary,\n",
        "            'pdf_url': paper.pdf_url,\n",
        "            'published': str(paper.published.date())\n",
        "        }\n",
        "        papers_info[paper.get_short_id()] = paper_info\n",
        "\n",
        "    # Save updated papers_info to json file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(papers_info, json_file, indent=2)\n",
        "\n",
        "    print(f\"Results are saved in: {file_path}\")\n",
        "\n",
        "    return paper_ids"
      ],
      "metadata": {
        "id": "jmQIaMDswjhH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## it will return the ids of the research papers related to the given topic\n",
        "search_papers(\"computers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTd8HxOgwsQD",
        "outputId": "3ecef5ce-f37a-4b71-b5f7-540c00e6f872"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results are saved in: papers/computers/papers_info.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1310.7911v2',\n",
              " 'math/9711204v1',\n",
              " '2208.00733v1',\n",
              " '2504.07020v1',\n",
              " '2403.03925v1']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
      ],
      "metadata": {
        "id": "wsKR6ERbw_O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info(paper_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific paper across all topic directories.\n",
        "\n",
        "    Args:\n",
        "        paper_id: The ID of the paper to look for\n",
        "\n",
        "    Returns:\n",
        "        JSON string with paper information if found, error message if not found\n",
        "    \"\"\"\n",
        "\n",
        "    for item in os.listdir(PAPER_DIR):\n",
        "        item_path = os.path.join(PAPER_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        papers_info = json.load(json_file)\n",
        "                        if paper_id in papers_info:\n",
        "                            return json.dumps(papers_info[paper_id], indent=2)\n",
        "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    return f\"There's no saved information related to paper {paper_id}.\""
      ],
      "metadata": {
        "id": "QiUPHq6kwv3c"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_info('1310.7911v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "bunaN-q6xDCG",
        "outputId": "db6dc527-30f0-4423-bccc-64d217873e34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Schema"
      ],
      "metadata": {
        "id": "w6SkBD96xLH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"name\": \"search_papers\",\n",
        "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"topic\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The topic to search for\"\n",
        "                },\n",
        "                \"max_results\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Maximum number of results to retrieve\",\n",
        "                    \"default\": 5\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"topic\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"extract_info\",\n",
        "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"paper_id\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The ID of the paper to look for\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"paper_id\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "yj5mIR5CxGCU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Mapping"
      ],
      "metadata": {
        "id": "OhtH9D5KxSLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_tool_function = {\n",
        "    \"search_papers\": search_papers,\n",
        "    \"extract_info\": extract_info\n",
        "}\n",
        "\n",
        "def execute_tool(tool_name, tool_args):\n",
        "\n",
        "    result = mapping_tool_function[tool_name](**tool_args)\n",
        "\n",
        "    if result is None:\n",
        "        result = \"The operation completed but didn't return any results.\"\n",
        "\n",
        "    elif isinstance(result, list):\n",
        "        result = ', '.join(result)\n",
        "\n",
        "    elif isinstance(result, dict):\n",
        "        # Convert dictionaries to formatted JSON strings\n",
        "        result = json.dumps(result, indent=2)\n",
        "\n",
        "    else:\n",
        "        # For any other type, convert using str()\n",
        "        result = str(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "pzsItDG7xO5z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbot code"
      ],
      "metadata": {
        "id": "Q3YWFGrMy1nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=CLAUDE_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "3y2PI_2lxVtm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(query):\n",
        "\n",
        "    messages = [{'role': 'user', 'content': query}]\n",
        "\n",
        "    response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "    process_query = True\n",
        "    while process_query:\n",
        "        assistant_content = []\n",
        "\n",
        "        for content in response.content:\n",
        "            if content.type == 'text':\n",
        "\n",
        "                print(content.text)\n",
        "                assistant_content.append(content)\n",
        "\n",
        "                if len(response.content) == 1:\n",
        "                    process_query = False\n",
        "\n",
        "            elif content.type == 'tool_use':\n",
        "\n",
        "                assistant_content.append(content)\n",
        "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
        "\n",
        "                tool_id = content.id\n",
        "                tool_args = content.input\n",
        "                tool_name = content.name\n",
        "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
        "\n",
        "                result = execute_tool(tool_name, tool_args)\n",
        "                messages.append({\"role\": \"user\",\n",
        "                                  \"content\": [\n",
        "                                      {\n",
        "                                          \"type\": \"tool_result\",\n",
        "                                          \"tool_use_id\": tool_id,\n",
        "                                          \"content\": result\n",
        "                                      }\n",
        "                                  ]\n",
        "                                })\n",
        "                response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
        "                    print(response.content[0].text)\n",
        "                    process_query = False"
      ],
      "metadata": {
        "id": "5CWuDDjpy6tv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat loop"
      ],
      "metadata": {
        "id": "nTbEDYOYzDEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_loop():\n",
        "    print(\"Type your queries or 'quit' to exit.\")\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nQuery: \").strip()\n",
        "            if query.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            process_query(query)\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError: {str(e)}\")"
      ],
      "metadata": {
        "id": "cwVPNaUPzBF_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySMOOcYMzPpv",
        "outputId": "24d013f1-3951-4ab6-d523-2ad00d5b5bd9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type your queries or 'quit' to exit.\n",
            "\n",
            "Query: HI\n",
            "\n",
            "Error: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
            "\n",
            "Query: QUIT\n"
          ]
        }
      ]
    }
  ]
}